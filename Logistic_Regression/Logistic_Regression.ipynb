{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "In this code, we will explore the concept of [*Logistic Regression*](https://en.wikipedia.org/wiki/Logistic_regression) and its application for sentimental analysis. \n",
    "\n",
    "The goal is to use the [amazon_baby_subset.csv](../Data/amazon_baby_subset.csv), which contains 4 columns: Product name, client review, client rate, and sentiment. The rating goes from 1 (worst) to 5 (best) and the sentiment is -1 if the rating is low (< 3) and 1 if it is good (>= 3). Here, the logistic regression method is used to give weights to each important word in the comments (the important words are given now. In the future, we will see how to select them) and to create a prediction model for future reviews, understanting if it is good or bad.\n",
    "\n",
    "First, let's load all used packages and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mguarido/anaconda2/envs/venv/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import turicreate as tc\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /mnt/hgfs/OneDrive/Machine_Learning/Data/amazon_baby_subset.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /mnt/hgfs/OneDrive/Machine_Learning/Data/amazon_baby_subset.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.893849 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.893849 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,int,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /mnt/hgfs/OneDrive/Machine_Learning/Data/amazon_baby_subset.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /mnt/hgfs/OneDrive/Machine_Learning/Data/amazon_baby_subset.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 53072 lines in 0.396983 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 53072 lines in 0.396983 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "products = tc.SFrame('../Data/amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">review</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">rating</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Stop Pacifier Sucking<br>without tears with ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">All of my kids have cried<br>non-stop when I tried to ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Nature's Lullabies Second<br>Year Sticker Calendar ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">We wanted to get<br>something to keep track ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Nature's Lullabies Second<br>Year Sticker Calendar ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">My daughter had her 1st<br>baby over a year ago. ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Lamaze Peekaboo, I Love<br>You ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">One of baby's first and<br>favorite books, and i ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">SoftPlay Peek-A-Boo<br>Where's Elmo A Childr ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Very cute interactive<br>book! My son loves this ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Our Baby Girl Memory Book</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Beautiful book, I love it<br>to record cherished t ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Hunnt&amp;reg; Falling<br>Flowers and Birds Kids ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Try this out for a spring<br>project !Easy ,fun and ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Blessed By Pope Benedict<br>XVI Divine Mercy Full ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">very nice Divine Mercy<br>Pendant of Jesus now on ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cloth Diaper Pins<br>Stainless Steel ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">We bought the pins as my<br>6 year old Autistic son ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cloth Diaper Pins<br>Stainless Steel ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">It has been many years<br>since we needed diaper ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 4 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\treview\tstr\n",
       "\trating\tint\n",
       "\tsentiment\tint\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+-------------------------------+-------------------------------+--------+-----------+\n",
       "|              name             |             review            | rating | sentiment |\n",
       "+-------------------------------+-------------------------------+--------+-----------+\n",
       "| Stop Pacifier Sucking with... | All of my kids have cried ... |   5    |     1     |\n",
       "| Nature's Lullabies Second ... | We wanted to get something... |   5    |     1     |\n",
       "| Nature's Lullabies Second ... | My daughter had her 1st ba... |   5    |     1     |\n",
       "|  Lamaze Peekaboo, I Love You  | One of baby's first and fa... |   4    |     1     |\n",
       "| SoftPlay Peek-A-Boo Where'... | Very cute interactive book... |   5    |     1     |\n",
       "|   Our Baby Girl Memory Book   | Beautiful book, I love it ... |   5    |     1     |\n",
       "| Hunnt&reg; Falling Flowers... | Try this out for a spring ... |   5    |     1     |\n",
       "| Blessed By Pope Benedict X... | very nice Divine Mercy Pen... |   5    |     1     |\n",
       "| Cloth Diaper Pins Stainles... | We bought the pins as my 6... |   4    |     1     |\n",
       "| Cloth Diaper Pins Stainles... | It has been many years sin... |   5    |     1     |\n",
       "+-------------------------------+-------------------------------+--------+-----------+\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count how many positive and negative reviews the data set has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews = 26579\n",
      "Number of negative reviews = 26493\n"
     ]
    }
   ],
   "source": [
    "print 'Number of positive reviews =', len(products[products['sentiment']==1])\n",
    "print 'Number of negative reviews =', len(products[products['sentiment']==-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty close numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the reviews are writen have punctuation. Let's clean them and also create columns with the important words count. The important words are in the file [important_words.json](../Data/important_words.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the important words from the *json* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baby', 'one', 'great', 'love', 'use', 'would', 'like', 'easy', 'little', 'seat', 'old', 'well', 'get', 'also', 'really', 'son', 'time', 'bought', 'product', 'good', 'daughter', 'much', 'loves', 'stroller', 'put', 'months', 'car', 'still', 'back', 'used', 'recommend', 'first', 'even', 'perfect', 'nice', 'bag', 'two', 'using', 'got', 'fit', 'around', 'diaper', 'enough', 'month', 'price', 'go', 'could', 'soft', 'since', 'buy', 'room', 'works', 'made', 'child', 'keep', 'size', 'small', 'need', 'year', 'big', 'make', 'take', 'easily', 'think', 'crib', 'clean', 'way', 'quality', 'thing', 'better', 'without', 'set', 'new', 'every', 'cute', 'best', 'bottles', 'work', 'purchased', 'right', 'lot', 'side', 'happy', 'comfortable', 'toy', 'able', 'kids', 'bit', 'night', 'long', 'fits', 'see', 'us', 'another', 'play', 'day', 'money', 'monitor', 'tried', 'thought', 'never', 'item', 'hard', 'plastic', 'however', 'disappointed', 'reviews', 'something', 'going', 'pump', 'bottle', 'cup', 'waste', 'return', 'amazon', 'different', 'top', 'want', 'problem', 'know', 'water', 'try', 'received', 'sure', 'times', 'chair', 'find', 'hold', 'gate', 'open', 'bottom', 'away', 'actually', 'cheap', 'worked', 'getting', 'ordered', 'came', 'milk', 'bad', 'part', 'worth', 'found', 'cover', 'many', 'design', 'looking', 'weeks', 'say', 'wanted', 'look', 'place', 'purchase', 'looks', 'second', 'piece', 'box', 'pretty', 'trying', 'difficult', 'together', 'though', 'give', 'started', 'anything', 'last', 'company', 'come', 'returned', 'maybe', 'took', 'broke', 'makes', 'stay', 'instead', 'idea', 'head', 'said', 'less', 'went', 'working', 'high', 'unit', 'seems', 'picture', 'completely', 'wish', 'buying', 'babies', 'won', 'tub', 'almost', 'either']\n"
     ]
    }
   ],
   "source": [
    "with open('../Data/important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]\n",
    "print important_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's remove the reviews punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to count each important word and create new columns with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: int\n",
       "Rows: 53072\n",
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 7, 0, 0, 1, 0, 0, 0, 0, 0, 0, 13, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, ... ]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[important_words[0]] # This is the count of the word 'baby' for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12174"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products[products[important_words[0]] > 0]) # Number of reviews that contain the word 'baby'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many time the word *baby* appears in all the reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18715"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(products['baby'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression deals with categorical variables, and here in the sentimental analysis, it assumes only 2 number: 1 for a good review and -1 for a bad review.\n",
    "\n",
    "The whole idea is to estimate the probabily on which the review is good or bad, and the probability is computed usin the [logistic function](https://en.wikipedia.org/wiki/Logistic_function) (also known as link function):\n",
    "\n",
    "$$ P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + e^{-\\mathbf{w}^T h(\\mathbf{x}_i)}} $$\n",
    "\n",
    "where, in our code, the feature vector $h(\\mathbf{x}_i)$ represents the word counts of **important_words** in the review $\\mathbf{x}_i$. In this equation, for a given vector of weights $\\mathbf{w}$ and the word count $\\mathbf{x}_i$, it computes the probabilty of the sentiment $\\mathbf{i}_i$ be positive (equal to 1). The values go from 0 to 1. We can choose a threshold (usually 0.5) on which a higher probability is considered as a positive sentiment, while the opsite comes from a lower probability.\n",
    "\n",
    "Best prediction comes from optimized weights. And a good way to obtain such weights is by [maximizing the likelihood function](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation). The [likelihood function](https://en.wikipedia.org/wiki/Likelihood_function) is writen as:\n",
    "\n",
    "$$\\ell(\\mathbf{w}) = \\prod_{i = 1}^{N}P(y_i | \\mathbf{x}_i,\\mathbf{w})$$\n",
    "\n",
    "The optimization method can be done by by the gradient descent method. To find the optimized weights, we should derive the likelihood function by $\\mathbf{w}$. However, such task is not easy for the current function. A good strategy is to work with the [natural logarithm](https://en.wikipedia.org/wiki/Natural_logarithm) of the likelihood function, called the **log-likelihood**.\n",
    "\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\ln\\prod_{i = 1}^{N}P(y_i | \\mathbf{x}_i,\\mathbf{w}) = \\sum_{i = 1}^{N}\\ln P(y_i | \\mathbf{x}_i,\\mathbf{w})$$\n",
    "\n",
    "The log-likelihood can be computed using the following formula:\n",
    "\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\{ (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln[1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))]\\} $$\n",
    "\n",
    "The derivative of the log-likelihood is:\n",
    "\n",
    "$$\\frac{\\partial\\ell\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)$$\n",
    "\n",
    "where $\\mathbf{1}[y_i = +1]$ means that it is equal 1 if the sentment is positive (1) and 0 if the sentiment is negative (-1). Now that we can compute the gradient of the log-likelihood, the gradient descent method can be applied:\n",
    "\n",
    "$$\\mathbf{w}_{j+1} = \\mathbf{w}_j + \\lambda\\frac{\\partial\\ell\\ell}{\\partial w_j}$$\n",
    "\n",
    "Great!!! Now let's implement the equations above to find the optimal weights $\\mathbf{w}$. Then we can use then to make predictions of the reviews sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to convert the Turicreate SFrame data to Numpy array to perform the math. The following function receives the SFrame data, the list of desired features (that will be the important words count), and the class label (in this case, 'sentiment'). It will return two outputs: a matrix with the features (word count) plus an initial intercept (= 1), and an array with the sentiment (-1 or +1) of each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, label):\n",
    "    data_sframe['intercept'] = 1 # Initial value for the intercept, including it in the sframe\n",
    "    features = ['intercept'] + features # Including 'intercept' in the features array\n",
    "    features_sframe = data_sframe[features] # Saving a sframe with only the desired features \n",
    "    feature_matrix = features_sframe.to_numpy() # Converting the features sframe to a numpy array (matrix)\n",
    "    label_sarray = data_sframe[label] # Picking the desired label\n",
    "    label_array = label_sarray.to_numpy() # Converting the label to a numpy array\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53072\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "print len(products[products['sentiment']]) # Number of reviews\n",
    "print len(important_words) + 1 # Number of features plus the intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the *feature_matrix* matches in size the number of reviews and the number of features (plus the intercept).\n",
    "\n",
    "Let's now create a function to calculate the probability for positive sentiments (the negative sentiment probability is just one minus the positive sentiment probability), given an array of coefficients and the feature matrix. The output is an array with the probability predictions for each reviews (or length of the feature matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(coefficients, feature_matrix):\n",
    "    # Computing P(y_i = +1 | x_i, w), using the logistic function\n",
    "    predictions = 1/(1 + np.exp(-np.dot(coefficients, feature_matrix)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. The function accepts two arguments:\n",
    "* **errors** vector containing $\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$ for all $i$.\n",
    "* **feature** vector containing $h_j(\\mathbf{x}_i)$  for all $i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
